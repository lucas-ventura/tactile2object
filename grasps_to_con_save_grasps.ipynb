{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organized-battle",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pymeshlab\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "every-hardware",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ycb_dir = \"ycb\"\n",
    "\n",
    "# Path to the directory with all the folders with the pickle pressure files\n",
    "pressure_path = \"C:/Users/lucas/Desktop/UPC/MIT/manopth/outputs/graspit_to_mano/ycb/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-answer",
   "metadata": {},
   "source": [
    "# Convert pressure info to pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "square-constitutional",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pressure_pointcloud_path = os.path.join(ycb_dir, \"5_pressure_pointcloud\")\n",
    "\n",
    "if not os.path.exists(pressure_pointcloud_path):\n",
    "    os.makedirs(pressure_pointcloud_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-system",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_obj_name = lambda name : name[:len(name) - 14]\n",
    "obj_names = []\n",
    "\n",
    "for obj_folder in os.listdir(pressure_path):\n",
    "\n",
    "    pkls_path = os.path.join(pressure_path, obj_folder)\n",
    "    obj_name = get_obj_name(obj_folder)\n",
    "    obj_names.append(obj_name)\n",
    "    \n",
    "    # Get sensor info from every pkl file\n",
    "    all_sensors_xyz = []\n",
    "    all_sensors_pressure = []\n",
    "\n",
    "    for pkl_name in os.listdir(pkls_path):\n",
    "        pkl_path = os.path.join(pkls_path, pkl_name)\n",
    "\n",
    "\n",
    "        pressure_info = pickle.load( open( pkl_path, \"rb\") )\n",
    "\n",
    "        # Load the sensors pressure and take only the ones that have pressure greater than 0\n",
    "        sensors_pressure = pressure_info['sensors_pressure']\n",
    "        idx_sensors = np.nonzero(sensors_pressure)\n",
    "\n",
    "        sensors_xyz = pressure_info['sensors_xyz'][idx_sensors]\n",
    "        sensors_pressure = sensors_pressure[idx_sensors]\n",
    "\n",
    "        all_sensors_xyz.append(sensors_xyz)\n",
    "        all_sensors_pressure.append(sensors_pressure)\n",
    "\n",
    "    sensors_xyz = np.concatenate(all_sensors_xyz)\n",
    "    sensors_pressure = np.concatenate(all_sensors_pressure)\n",
    "\n",
    "    # Point cloud of the geneated object\n",
    "    pcd_gen = o3d.geometry.PointCloud()\n",
    "    pcd_gen.points = o3d.utility.Vector3dVector(sensors_xyz)\n",
    "\n",
    "    pcd_gen.estimate_normals()\n",
    "    pcd_gen.orient_normals_consistent_tangent_plane(50)\n",
    "    \n",
    "    ply_pth = os.path.join(pressure_pointcloud_path, f\"{obj_name}.ply\")\n",
    "    o3d.io.write_point_cloud(ply_pth, pcd_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-windsor",
   "metadata": {},
   "source": [
    "# Generate data for Convolutional Occupancy Networks\n",
    "Generate the pointcloud.npz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "norman-olympus",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pressure_points_path = os.path.join(ycb_dir, \"6_pressure_pointcloud\")\n",
    "\n",
    "if not os.path.exists(pressure_points_path):\n",
    "    os.makedirs(pressure_points_path)\n",
    "    \n",
    "for obj_name in obj_names:\n",
    "    pc_pth = os.path.join(ycb_dir, \"4_pointcloud\", f\"{obj_name}.npz\")\n",
    "    pc_npz = np.load(pc_pth)\n",
    "\n",
    "    translation = pc_npz['loc'].tolist()\n",
    "    scale = pc_npz['scale'].item()\n",
    "\n",
    "    ply_pth = os.path.join(pressure_pointcloud_path, f\"{obj_name}.ply\")\n",
    "    pcd_pressure = o3d.io.read_point_cloud(ply_pth)\n",
    "\n",
    "    points = (np.asarray(pcd_pressure.points) - translation) / scale\n",
    "    normals = np.asarray(pcd_pressure.normals)\n",
    "\n",
    "    npz_pth = os.path.join(pressure_points_path, obj_name)\n",
    "    np.savez(npz_pth, \n",
    "             points=points, \n",
    "             normals=normals,\n",
    "             loc=pc_npz['loc'],\n",
    "             scale=pc_npz['scale']\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-powder",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pregnant-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pth = os.path.join(ycb_dir, \"ycb_con\")\n",
    "\n",
    "if not os.path.exists(dataset_pth):\n",
    "    os.makedirs(dataset_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "painful-saturday",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for obj_name in obj_names:\n",
    "    obj_dir = os.path.join(dataset_pth, obj_name)\n",
    "    \n",
    "    if not os.path.exists(obj_dir):\n",
    "        os.makedirs(obj_dir)\n",
    "        \n",
    "    src_pth_ps = os.path.join(ycb_dir, \"4_points\", f\"{obj_name}.npz\")\n",
    "    dst_pth_ps = os.path.join(obj_dir, \"points.npz\")\n",
    "    copyfile(src_pth_ps, dst_pth_ps)\n",
    "    \n",
    "    src_pth_pcd = os.path.join(pressure_points_path, f\"{obj_name}.npz\")\n",
    "    dst_pth_pcd = os.path.join(obj_dir, \"pointcloud.npz\")\n",
    "    copyfile(src_pth_pcd, dst_pth_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "veterinary-queen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create splits\n"
     ]
    }
   ],
   "source": [
    "# Create splits\n",
    "print(\"Create splits\")\n",
    "n = len(obj_names)\n",
    "n_train, n_val = int(n * 0.6), int(n * 0.2)\n",
    "n_test = n - n_train - n_val\n",
    "\n",
    "np.random.shuffle(obj_names)\n",
    "\n",
    "training, val, test = obj_names[:n_train], obj_names[n_train:(n_train + n_val)], obj_names[-n_test:]\n",
    "train_pth = os.path.join(dataset_pth, 'train.lst')\n",
    "val_pth = os.path.join(dataset_pth, 'val.lst')\n",
    "test_pth = os.path.join(dataset_pth, 'test.lst')\n",
    "\n",
    "with open(train_pth, 'w') as filehandle:\n",
    "    for obj_name in training:\n",
    "        filehandle.write('%s\\n' % obj_name)\n",
    "\n",
    "with open(val_pth, 'w') as filehandle:\n",
    "    for obj_name in val:\n",
    "        filehandle.write('%s\\n' % obj_name)\n",
    "\n",
    "with open(test_pth, 'w') as filehandle:\n",
    "    for obj_name in test:\n",
    "        filehandle.write('%s\\n' % obj_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
